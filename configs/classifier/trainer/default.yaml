# @package _global_
# Transformer classifier training configuration

classifier:
  trainer:
    # Training hyperparameters
    epochs: 50
    lr: 0.0001
    weight_decay: 0.01
    batch_size: 64

    # Learning rate schedule
    warmup_steps: 1000
    lr_schedule: cosine   # "cosine" or "constant"

    # Loss function
    label_smoothing: 0.0  # Label smoothing factor (0.0 = no smoothing)

    # Metrics to compute
    metrics:
      - acc
      - auroc
      - f1

    # Reproducibility
    seed: 42

    # Gradient clipping
    grad_clip: 1.0

    # PID embedding experiment settings
    log_pid_embeddings: false       # Log PID embedding geometry per epoch (cosine sim, norms, isotropy)
    pid_schedule:
      mode: standard                # "standard" | "warmup_fixed" | "frozen_backbone"
      transition_epoch: 50          # Epoch at which the phase switch happens
      reinit_mode: normal           # "normal" (Gaussian) or "one_hot_padded" (only for frozen_backbone)
      pid_lr: null                  # Optional separate LR for PID-only phase (null = use main lr)

    # Early stopping
    early_stopping:
      enabled: false
      patience: 20
      min_delta: 0.0
      restore_best_weights: true
