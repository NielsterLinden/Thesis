# @package _global_
# PID Embedding Deep Dive — Warmup-Fixed Schedule
#
# Train with a FIXED (one-hot-padded) PID embedding for the first N epochs,
# then unfreeze and allow it to learn freely.
#
# For dim=8:  initialized as eye(8)
# For dim>8: initialized as [eye(8) | zeros(8, dim-8)]
#
# Sweep axes:
#   - id_embed_dim: 8, 16, 32
#   - pid_mode is always "learned" (starts one-hot-padded, then learns)
#
# The IdentityTokenizer is initialized in "one_hot" mode at construction.
# At transition_epoch the training loop unfreezes it → learned.
#
# Total runs: 3

experiment:
  name: "pid_deepdive_warmup"

hydra:
  mode: MULTIRUN
  job:
    chdir: true
    name: ${experiment.name}
  run:
    dir: ${env.output_root}/runs/run_${now:%Y%m%d-%H%M%S}_${experiment.name}_job${zpad:${hydra.job.num}}
  sweep:
    dir: ${env.output_root}/multiruns/exp_${now:%Y%m%d-%H%M%S}_${experiment.name}
    subdir: ${env.output_root}/runs/run_${now:%Y%m%d-%H%M%S}_${experiment.name}_job${zpad:${hydra.job.num}}
  sweeper:
    params:
      classifier.model.tokenizer.id_embed_dim: 8,16,32
      classifier.trainer.epochs: 100
      classifier.trainer.log_pid_embeddings: true

meta:
  goal: "classification"

classifier:
  model:
    tokenizer:
      name: identity
      # Start with fixed one-hot (will be unfrozen at transition_epoch)
      pid_mode: one_hot
  trainer:
    pid_schedule:
      mode: warmup_fixed
      transition_epoch: 50     # Unfreeze PID at this epoch

data:
  classifier:
    signal_vs_background:
      signal: 1
      background: [2, 3, 4, 5]
