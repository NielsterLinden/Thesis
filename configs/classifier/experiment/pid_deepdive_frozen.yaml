# @package _global_
# PID Embedding Deep Dive — Frozen Backbone Schedule
#
# Phase 1 (epochs 0 .. transition_epoch-1):
#   Train the FULL model normally (learned PID + backbone).
# Phase 2 (epochs transition_epoch .. end):
#   Freeze the entire backbone, re-initialize the PID embedding from
#   scratch, and train ONLY the PID embedding.
#
# This tests whether the PID embedding can recover useful structure
# when the backbone is already trained — i.e., how much does the rest
# of the network rely on specific PID geometry?
#
# Sweep axes:
#   - id_embed_dim: 8, 16, 32
#
# Total runs: 3

experiment:
  name: "pid_deepdive_frozen"

hydra:
  mode: MULTIRUN
  job:
    chdir: true
    name: ${experiment.name}
  run:
    dir: ${env.output_root}/runs/run_${now:%Y%m%d-%H%M%S}_${experiment.name}_job${zpad:${hydra.job.num}}
  sweep:
    dir: ${env.output_root}/multiruns/exp_${now:%Y%m%d-%H%M%S}_${experiment.name}
    subdir: ${env.output_root}/runs/run_${now:%Y%m%d-%H%M%S}_${experiment.name}_job${zpad:${hydra.job.num}}
  sweeper:
    params:
      classifier.model.tokenizer.id_embed_dim: 8,16,32
      classifier.trainer.epochs: 100
      classifier.trainer.log_pid_embeddings: true

meta:
  goal: "classification"

classifier:
  model:
    tokenizer:
      name: identity
      pid_mode: learned           # Start learned, Phase 2 re-inits
  trainer:
    pid_schedule:
      mode: frozen_backbone
      transition_epoch: 50        # Freeze backbone + re-init PID at this epoch
      reinit_mode: normal         # "normal" (Gaussian) or "one_hot_padded"

data:
  classifier:
    signal_vs_background:
      signal: 1
      background: [2, 3, 4, 5]
