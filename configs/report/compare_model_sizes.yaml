# Hydra config for report: compare_model_sizes
#
# Compares classifier performance across different model sizes:
# - dim (model dimension)
# - depth (number of layers)
# - heads (number of attention heads)
# Optionally grouped by positional encoding type.

inputs:
  sweep_dir: null           # Path to experiment directory
  run_dirs: []              # Alternative: explicit list of run dirs
  select:
    dim: null               # e.g., [64, 128, 256, 512]
    depth: null             # e.g., [2, 4, 6, 8]
    positional: null        # e.g., [none, sinusoidal, rotary]
    seed: null              # e.g., [42, 43, 44]

report_name: compare_model_sizes

outputs:
  report_subdir: report
  fig_format: png
  dpi: 150
  which_figures:
    # Training comparison plots
    - all_val_curves
    - all_train_curves
    # Grouped by model size
    - val_loss_by_size
    - val_auroc_by_size
    # Grouped by positional encoding
    - val_loss_by_positional
    - val_auroc_by_positional
    # Inference plots (requires inference.enabled=true)
    - roc_curves
    - metrics_comparison
    - confusion_matrices
    - score_distributions
    # Grouped ROC curves
    - roc_curves_by_size
    - roc_curves_by_positional
    # AUROC bar charts
    - auroc_bar_by_size
    - auroc_bar_by_positional
    # Grid heatmaps
    - grid_auroc_size_vs_positional

thresholds:
  val_acc: 0.8
  comparison: ge
  split: val

summary_schema_version: 1

inference:
  enabled: true             # Enable to run inference during report generation
  persist_raw_scores: false # If true, save per-event scores
  dataset_split: test       # Which split to evaluate on
  autocast: true
  batch_size: 512
  seed: 42
  n_points_roc: 250
  max_samples: null         # Limit number of samples for testing (null = use all data)

env:
  output_root: null         # Auto-inferred from sweep_dir path, or set explicitly
