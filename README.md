# Thesis ML: Modular Framework for Particle Physics Machine Learning

A production-ready, reproducible machine learning framework for particle physics experiments, built with Hydra configuration management and designed for both local development and HPC deployment.

## ğŸ¯ Overview

This codebase provides a structured environment for training autoencoder variants, running experiments, and generating comparative analysis reports. It emphasizes:

- **Modularity**: Easy to add new architectures, training loops, and analysis types
- **Reproducibility**: Hydra-based configuration tracking and comprehensive facts logging
- **Scalability**: Seamless deployment from laptop to HPC cluster (Stoomboot at Nikhef)
- **Maintainability**: Clear separation between training, monitoring, and reporting phases

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone <repository-url>
cd Niels_repo

# Create conda environment
mamba env create -f environment.yml
mamba activate thesis-ml

# Install in editable mode
pip install -e .
```

### Run a Training

```bash
# Simple autoencoder training (local)
thesis-train

# Or using Python module
python -m thesis_ml.cli.train

```

### Generate a Report

```bash
# Compare multiple runs
thesis-report --config-name compare_tokenizers \
    inputs.sweep_dir=outputs/multiruns/exp_20251103_experiment

# Or using Python module
python -m thesis_ml.cli.reports --config-name compare_tokenizers \
    inputs.sweep_dir=outputs/multiruns/exp_20251103_experiment
```

## ğŸ“ Project Structure

```
src/thesis_ml/
â”œâ”€â”€ cli/                    # Command-line entry points
â”‚   â”œâ”€â”€ train/              # Training CLI (thesis-train)
â”‚   â””â”€â”€ reports/            # Reports CLI (thesis-report)
â”‚
â”œâ”€â”€ training_loops/         # Training loop implementations
â”‚   â”œâ”€â”€ autoencoder.py      # Standard autoencoder
â”‚   â”œâ”€â”€ gan_autoencoder.py  # GAN-based autoencoder
â”‚   â”œâ”€â”€ diffusion_autoencoder.py
â”‚   â””â”€â”€ simple_mlp.py       # Simple MLP for testing
â”‚
â”œâ”€â”€ architectures/          # Model architectures
â”‚   â”œâ”€â”€ autoencoder/        # Autoencoder components
â”‚   â”‚   â”œâ”€â”€ encoders/       # Encoder architectures (MLP, GNN, etc.)
â”‚   â”‚   â”œâ”€â”€ decoders/       # Decoder architectures
â”‚   â”‚   â”œâ”€â”€ bottlenecks/    # Latent space types (VQ, linear, identity)
â”‚   â”‚   â””â”€â”€ losses/         # Loss functions
â”‚   â””â”€â”€ simple/             # Simple architectures (MLP)
â”‚
â”œâ”€â”€ facts/                  # Training metrics & events system
â”‚   â”œâ”€â”€ builders.py         # Build standardized event payloads
â”‚   â”œâ”€â”€ writers.py          # Write facts to disk (JSONL, CSV)
â”‚   â””â”€â”€ readers.py          # Read facts for reports
â”‚
â”œâ”€â”€ monitoring/             # Training-time visualization
â”‚   â”œâ”€â”€ orchestrator.py     # Route events to plot families
â”‚   â”œâ”€â”€ io_utils.py         # Figure saving utilities
â”‚   â””â”€â”€ families/           # Plot families (losses, metrics, etc.)
â”‚
â”œâ”€â”€ reports/                # Post-training analysis
â”‚   â”œâ”€â”€ analyses/           # Analysis implementations
â”‚   â”‚   â”œâ”€â”€ compare_tokenizers.py
â”‚   â”‚   â””â”€â”€ compare_globals_heads.py
â”‚   â”œâ”€â”€ inference/          # Inference utilities
â”‚   â”œâ”€â”€ plots/              # Report plotting functions
â”‚   â””â”€â”€ utils/              # Report utilities
â”‚
â”œâ”€â”€ data/                   # Dataset loaders
â”‚   â”œâ”€â”€ h5_loader.py        # HDF5 dataset loader
â”‚   â””â”€â”€ synthetic.py        # Synthetic data generation
â”‚
â””â”€â”€ utils/                  # General utilities
    â”œâ”€â”€ seed.py             # Reproducibility utilities
    â”œâ”€â”€ paths.py            # Path management
    â””â”€â”€ training_progress_shower.py
```

## ğŸ”‘ Key Concepts

### Facts System

The **facts system** is the backbone of reproducibility and analysis:

- **Events** (`events.jsonl`): Lifecycle events (on_start, on_epoch_end, on_train_end) with full training histories
- **Scalars** (`scalars.csv`): Per-epoch metrics for easy DataFrame analysis
- **Purpose**: Enables post-hoc analysis without re-running expensive training

All training loops emit facts to `{run_dir}/facts/`. Reports read these facts to generate analyses.

### Training â†’ Monitoring â†’ Reports Pipeline

1. **Training**: Run a training loop (e.g., `autoencoder.py`)
   - Emits facts via `facts.writers`
   - Optionally creates real-time plots via `monitoring.orchestrator`

2. **Monitoring**: Real-time visualization during training
   - Plot families (losses, metrics, reconstruction, etc.)
   - Configured via `logging` config group

3. **Reports**: Post-training analysis
   - Read facts via `facts.readers`
   - Generate comparative plots
   - Run inference on test data
   - Output to `outputs/reports/`

### Environment Switching (Local â†” HPC)

Switch between local and Stoomboot (Nikhef HPC) via Hydra:

```bash
# Local (default paths)
thesis-train env=local

# Stoomboot
thesis-train env=stoomboot
```

Paths are automatically configured:
- **Local**: Data in `C:\...\Data`, outputs in `outputs/`
- **Stoomboot**: Data in `/data/atlas/users/nterlind/datasets`, outputs in `/data/atlas/users/nterlind/outputs`

## ğŸ“š Documentation

- **[ARCHITECTURE.md](ARCHITECTURE.md)**: System design and data flow
- **[TRAINING_GUIDE.md](TRAINING_GUIDE.md)**: Using and creating training code
- **[REPORTS_GUIDE.md](REPORTS_GUIDE.md)**: Using and creating reports
- **[FACTS_SYSTEM.md](FACTS_SYSTEM.md)**: Facts architecture in detail
- **[CONFIGS_GUIDE.md](CONFIGS_GUIDE.md)**: Hydra configuration patterns
- **[HPC_GUIDE.md](HPC_GUIDE.md)**: Running on Stoomboot cluster
- **[DEVELOPMENT_GUIDE.md](DEVELOPMENT_GUIDE.md)**: Contributing and development setup

## ğŸ“ Typical Workflows

### Local Development

```bash
# 1. Quick smoke test (3 epochs, no artifacts)
thesis-train phase1.trainer.epochs=3 logging.save_artifacts=false

# 2. Full training run with plots
thesis-train phase1.trainer.epochs=20 logging=plots_standard

# 3. Experiment sweep (try different latent spaces)
thesis-train --multirun hydra=experiment \
    phase1/latent_space=none,linear,vq \
    phase1.trainer.epochs=20
```

### HPC Deployment

```bash
# Submit to Stoomboot cluster
condor_submit hpc/stoomboot/train.sub

# Monitor job
condor_q
```

### Analysis & Reporting

```bash
# Generate comparison report from sweep
thesis-report --config-name compare_tokenizers \
    inputs.sweep_dir=outputs/multiruns/exp_20251103-140953_experiment \
    inference.enabled=true

# Output: outputs/reports/report_TIMESTAMP_compare_tokenizers/
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run specific test file
pytest tests/test_phase1_assembly.py

# Smoke test (minimal imports)
pytest tests/test_smoke.py
```

## ğŸ› ï¸ Adding New Components

### New Training Loop

1. Create `src/thesis_ml/training_loops/my_loop.py`
2. Implement `def train(cfg: DictConfig) -> dict`
3. Register in `src/thesis_ml/cli/train/__init__.py`:
   ```python
   def _my_loop(cfg):
       from thesis_ml.training_loops.my_loop import train as _t
       return _t(cfg)

   DISPATCH = {
       ...,
       "my_loop": _my_loop,
   }
   ```
4. Run: `thesis-train loop=my_loop`

### New Architecture

1. Add encoder/decoder/bottleneck to `src/thesis_ml/architectures/autoencoder/`
2. Create config in `configs/phase1/encoder/` (or decoder/latent_space)
3. Run: `thesis-train phase1/encoder=my_encoder`

### New Report

1. Create `src/thesis_ml/reports/analyses/my_report.py`
2. Implement `def run_report(cfg: DictConfig) -> None`
3. Create config in `configs/report/my_report.yaml`
4. Run: `thesis-report --config-name my_report`

## ğŸ¤ Contributing

See [DEVELOPMENT_GUIDE.md](DEVELOPMENT_GUIDE.md) for:
- Code style guidelines
- Testing requirements
- Git workflow
- Documentation standards

## ğŸ“Š Output Directory Structure

```
outputs/
â”œâ”€â”€ runs/                   # Single training runs
â”‚   â””â”€â”€ run_YYYYMMDD-HHMMSS_[name]/
â”‚       â”œâ”€â”€ .hydra/         # Hydra config snapshot
â”‚       â”œâ”€â”€ facts/          # Training facts (events.jsonl, scalars.csv)
â”‚       â”œâ”€â”€ figures/        # Training-time plots
â”‚       â”œâ”€â”€ model.pt        # Saved model checkpoint
â”‚       â””â”€â”€ *.log           # Logs
â”‚
â”œâ”€â”€ multiruns/              # Multi-run experiments
â”‚   â””â”€â”€ exp_YYYYMMDD-HHMMSS_[name]/
â”‚       â””â”€â”€ (structure mirrors runs/)
â”‚
â””â”€â”€ reports/                # Generated reports
    â””â”€â”€ report_YYYYMMDD-HHMMSS_[name]/
        â”œâ”€â”€ manifest.yaml   # Report metadata
        â”œâ”€â”€ training/       # Training analysis
        â”‚   â”œâ”€â”€ summary.csv
        â”‚   â””â”€â”€ figures/
        â””â”€â”€ inference/      # Inference results (optional)
            â”œâ”€â”€ summary.json
            â””â”€â”€ figures/
```

## ğŸ† Design Philosophy

1. **Configuration over Code**: Use Hydra to change behavior without editing Python
2. **Facts-First**: Training emits facts; reports consume facts. Clean separation.
3. **Fail-Fast Validation**: Catch config errors early with guardrails
4. **HPC-Ready**: One codebase, multiple environments, no code changes
5. **Extensibility**: Adding new components should be straightforward

## ğŸ“„ License

[Specify your license here]

## ğŸ‘¤ Author

Niels ter Linde - Master's Thesis, Particle Physics
